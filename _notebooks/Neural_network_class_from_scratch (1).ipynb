{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network class from scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsdDXe7vF_mU"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTBsaOjVy-EN"
      },
      "source": [
        "\n",
        "class neural_net:\n",
        "  def __init__(self,input , y ,nodes_per_layer,activations , print_weights=False):\n",
        "#     x shape is  (3, 8)\n",
        "#     X  is \n",
        "#      [[ 3  4  3 33 23 53  3 33]\n",
        "#       [ 4  1  9 42 44 64 64 34]\n",
        "#       [ 2  2  4  2 25 72  2 42]]\n",
        "#     y shape is (2, 8)\n",
        "#     y  is \n",
        "#       [[1 0 1 0 0 1 1 1]\n",
        "#        [1 1 0 0 1 0 1 0]]\n",
        "\n",
        "    n=input.shape[0]\n",
        "    d=input.shape[1]\n",
        "    #initializing the weights\n",
        "\n",
        "    self.input=input\n",
        "    self.input_shape=self.input.shape        #n[0] x m .....3x8\n",
        "    self.num_samples=self.input.shape[0]           # 8\n",
        "    self.nodes_per_layer=nodes_per_layer\n",
        "    self.activations=activations\n",
        "    self.y=y                    #n[l] x 1   ............2x8\n",
        "    self.weights=[]\n",
        "    self.b=[]\n",
        "    layer_weights = torch.empty(self.nodes_per_layer[0]*d).normal_(mean=0,std=0.001).reshape(self.nodes_per_layer[0] , d)\n",
        "    layer_bias = torch.empty(self.nodes_per_layer[0]).normal_(mean=0,std=0.001).reshape( self.nodes_per_layer[0] , 1)  #10000 x 1\n",
        "    self.weights.append(layer_weights)\n",
        "    self.b.append(layer_bias)\n",
        "    if print_weights:\n",
        "      print( 'layer 1 weights shape is',layer_weights.shape)\n",
        "      print( 'layer 1 weights  is \\n',layer_weights)\n",
        "\n",
        "      print( 'layer 1 bias shape is',layer_bias.shape)\n",
        "      print( 'layer 1  bias  is',layer_bias)\n",
        "\n",
        "\n",
        "    for i in range(self.nodes_per_layer.shape[0]-1):    #[4,3,2]\n",
        "      layer_weights = torch.empty(self.nodes_per_layer[i+1]*self.nodes_per_layer[i]).normal_(mean=0,std=0.001).reshape(self.nodes_per_layer[i+1],self.nodes_per_layer[i])\n",
        "      self.weights.append(layer_weights)\n",
        "      layer_bias = torch.empty(self.nodes_per_layer[i+1]).normal_(mean=0,std=0.001).reshape( self.nodes_per_layer[i+1] , 1)\n",
        "      self.b.append(layer_bias)\n",
        "      if print_weights:\n",
        "        print( 'layer ',str(i+2) ,' weights shape is',layer_weights.shape)\n",
        "        print( 'layer ',str(i+2) ,' weights  is \\n',layer_weights)\n",
        "\n",
        "        print( 'layer ',str(i+2) ,' bias shape is',layer_bias.shape)\n",
        "        print( 'layer ',str(i+2) ,' bias  is \\n',layer_bias)\n",
        "\n",
        "    \n",
        "\n",
        "  def forward_propagation(self , input):\n",
        "\n",
        "    # print('forward propadation')\n",
        "    self.a=[]         #[4,1],[3,1],[2,1]\n",
        "    z=torch.mm(self.weights[0] , input.t()) + self.b[0]\n",
        "    self.layer_output =self.Activation(z,self.activations[0]) \n",
        "    self.a.append(self.layer_output)\n",
        "\n",
        "    for i in range(1,self.nodes_per_layer.shape[0]):    #[4,3,2]\n",
        "      z=torch.mm(self.weights[i] , self.layer_output) + self.b[i]\n",
        "      self.layer_output=self.Activation(z,self.activations[i]) \n",
        "      self.a.append(self.layer_output)\n",
        "      # print('layer ' , str(i+1) ,' output \\n',self.layer_output)\n",
        "\n",
        "    # print('a= \\n',self.a)\n",
        "    return self.a[-1]\n",
        "\n",
        "\n",
        "  def back_propagation(self ,lr=0.01):\n",
        "\n",
        "    self.dz=self.a.copy()\n",
        "    self.dw=self.weights.copy()\n",
        "    self.db=self.b.copy()\n",
        "\n",
        "    self.dz[-1]=2 * (self.a[-1].t() - self.y) * self.Activation_derivative(self.a[-1].t() , activation=self.activations[-1])\n",
        "    self.dw[-1]=torch.mm(self.dz[-1].t() , self.a[-2].t()) * (1/self.num_samples)\n",
        "    self.db[-1]=torch.sum(self.dz[-1].t(),axis=1,keepdims=True) * (1/self.num_samples)\n",
        "\n",
        "    for i in range(-(self.nodes_per_layer.shape[0]-2),1):    #[4,3,2]\n",
        "      i=-i             #1,0\n",
        "      self.dz[i]=torch.mm(self.dz[i+1] , self.weights[i+1] ) * self.Activation_derivative(self.a[i].t() , activation=self.activations[i])\n",
        "      self.db[i]=torch.sum(self.dz[i].t(),axis=1,keepdims=True) * (1/self.num_samples)\n",
        "\n",
        "      if(i!=0):\n",
        "        self.dw[i]=torch.mm(self.dz[i].t() , self.a[i-1].t()) * (1/self.num_samples)\n",
        "\n",
        "      elif(i==0):\n",
        "        self.dw[i]=torch.mm(self.dz[i].t() , self.input) * (1/self.num_samples)\n",
        "\n",
        "\n",
        "    self.gradient_discent(self.weights,self.dw,self.b,self.db,lr=lr)\n",
        "\n",
        "  def gradient_discent(self,w,dw,b,db,lr):\n",
        "    for i in range(len (self.weights)):\n",
        "      self.weights[i]=w[i]-lr * dw[i]\n",
        "      self.b[i]=self.b[i]-lr * db[i]\n",
        "\n",
        "    \n",
        "  def train(self,epochs , lr=0.01 , verbose=True):\n",
        "    self.loss=[]\n",
        "    for i in range(epochs):\n",
        "      if verbose: print ('epoch ',str(i+1) ,'/',epochs)\n",
        "      self.forward_propagation(self.input)\n",
        "      self.loss.append(torch.mean ( self.l2_loss( self.y , self.a[-1].t() ) ) )\n",
        "      self.back_propagation(lr=lr)\n",
        "      if verbose : print('loss= ',self.loss[i])\n",
        "      if verbose : print('-------'*10)\n",
        "\n",
        "    plt.plot(self.loss)\n",
        "    plt.ylabel('loss')\n",
        "    plt.show()\n",
        "\n",
        "    # self.accuracy(self.a[-1] , self.y)\n",
        "\n",
        "    return self.loss, self.a[-1]\n",
        "\n",
        "  def sigmoid(self,z):\n",
        "    s= 1/(1 + np.exp(-z)) \n",
        "    return s\n",
        "\n",
        "  def Relu(self,z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "  def tanh(self,z):\n",
        "    return (np.exp(z) - np.exp(-z))/(np.exp(z) + np.exp(-z))\n",
        "\n",
        "  def softmax(self,y):\n",
        "    exps = np.exp(y)\n",
        "    return exps / np.sum(exps)\n",
        "\n",
        "  def Activation(self,z,method='sigmoid'):\n",
        "    \n",
        "      if (method=='sigmoid'):\n",
        "        return self.sigmoid(z)\n",
        "      elif(method=='tanh'):\n",
        "        return self.tanh(z)\n",
        "      elif (method=='Relu'):\n",
        "        return self.Relu(z)\n",
        "      elif method==None:\n",
        "        return z\n",
        "      else :\n",
        "        return z\n",
        "        \n",
        "  def predict(self , input):\n",
        "\n",
        "    z=torch.mm(self.weights[0] , input.t()) + self.b[0]\n",
        "    layer_output =self.Activation(z,self.activations[0]) \n",
        "    for i in range(1,self.nodes_per_layer.shape[0]):    #[4,3,2]\n",
        "      z=torch.mm(self.weights[i] , layer_output) + self.b[i]\n",
        "      layer_output=self.Activation(z,self.activations[i]) \n",
        "\n",
        "\n",
        "    return layer_output\n",
        "\n",
        "\n",
        "  def Activation_derivative(self,a,activation='sigmoid'):\n",
        "    if (activation=='sigmoid'):\n",
        "      return a * (1-a)\n",
        "    elif (activation=='tanh'):\n",
        "      return 1-a**2\n",
        "    elif (activation=='Relu'):\n",
        "      return np.minimum(-np.maximum(0,z),1)\n",
        "\n",
        "  def l2_loss(self , y_pred , y):\n",
        "  # return torch.sum(torch.pow(y - y_pred ,2) , axis=1 ) #nx1\n",
        "    return torch.norm(y-y_pred , dim=1)**2\n",
        "  \n",
        " \n",
        "  def cross_entropy_loss(self,a, y):\n",
        "    return - np.mean(\n",
        "        np.multiply(y, np.log(a)) + np.multiply((1-y), np.log(1-a)))\n",
        "    \n",
        "  def accuracy(self , a , Y):\n",
        "    correct=0\n",
        "    for i in range(Y.shape[0]) :\n",
        "      if torch.argmax( a.t() , axis=1 )[i]==torch.argmax( Y , axis=1 )[i]:\n",
        "        correct+=1\n",
        "    acc=(correct / Y.shape[0]) * 100\n",
        "    print('accuracy = ', acc , '%')\n",
        "\n",
        "\n",
        " \n",
        "   \n",
        "  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xo3AzkDEzVeY"
      },
      "source": [
        "### Loading mnist dataset from keras.datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsJndhwVxOZy"
      },
      "source": [
        "Download MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUoD-xXRzEjF",
        "outputId": "5a021da9-ce13-4f2c-8bbf-de33b03acd5a"
      },
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train.astype('float32') / 255.0, x_test.astype('float32') / 255.0\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ABack5trqAX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12617f04-27fe-48fe-8a49-53807d6c36b0"
      },
      "source": [
        "x_train.shape , y_train.shape , x_test.shape , y_test.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meNfuSo-zddx"
      },
      "source": [
        "### preprocessing the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXXHu97jx7Lp"
      },
      "source": [
        "Convert each image to a vector of lenght 28x28 and each label to a one-hot vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No_yYjXmylJw"
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwJX3zYyzEgx"
      },
      "source": [
        "x_train = x_train.reshape(-1 , 28*28)\n",
        "x_test = x_test.reshape(-1 , 28*28)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "x_train = torch.from_numpy(x_train)\n",
        "x_test = torch.from_numpy(x_test)\n",
        "\n",
        "y_train = torch.from_numpy(y_train)\n",
        "y_test = torch.from_numpy(y_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5oj9iqyztye"
      },
      "source": [
        "### Creating the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4rMLFOSxX8T"
      },
      "source": [
        "Let's create a model with two layers. The first layer has 128 neurons and the second one has 10 neurons (number of MNISt classes). We will use tanh for the first layer and sigmoid for the second one."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0iMGhTzzEeY"
      },
      "source": [
        "nn=neural_net(x_train , y_train ,nodes_per_layer = np.array([128,10]) , activations=np.array(['tanh','sigmoid']) )   #  (self,input,nodes_per_layer,activations,y):"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9j9WyOozml0"
      },
      "source": [
        "### Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uT8Xl1lGzrH1",
        "outputId": "be31c9d8-e9f8-4d32-dcdc-cc50b0b1ea04"
      },
      "source": [
        "loss , y_pred = nn.train(epochs=1000 ,lr=0.1,verbose=False)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAJeSpMKz301"
      },
      "source": [
        "### Prediction for the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGj27I3OzlxQ",
        "outputId": "f8c171af-6ecc-4ec0-efdb-2725745bef8e"
      },
      "source": [
        "y_pred = nn.predict( x_test )\n",
        "nn.accuracy(y_pred,y_test)\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train accuracy =  84.59 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Itn63HcDwZAX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}